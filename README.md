# HelpAlertSystemforHospital
This system is a project designed to assist elderly and differently-abled individuals in communicating their needs to caregivers or emergency services. This project aims to provide a reliable and easy-to-use means of communication, reducing the risk of misunderstandings or errors. The system involves a device equipped with cameras like a web cam or smartphone camera, that detect eyeblinks or hand gestures and translate them into messages for help. These messages are then transmitted to a device, such as a smartphone or tablet, which alerts family members and caretakers for any help. The system is designed to be easy to use for individuals who may have limited mobility or verbal communication abilities, allowing users to activate the system by blinking or performing certain hand gestures. The key outcomes of the project include improved communication, increased independence, enhanced safety, improved response times, and increased peace of mind for caregivers and family members. By providing a more reliable and efficient means of communication, the project can help improve the quality of life for elderly and differently-abled individuals, reducing the risk of medical emergencies and enabling them to maintain their independence. The system provides an added layer of safety, enabling individuals to call for help in case of an emergency and ensuring that they receive prompt and appropriate assistance.
The main hardware component required for the system is a camera, which can either be a cell phone camera or a web cam. The camera is used to detect eyeblinks or hand gestures, which are then translated into messages for help. The main software component of the project is the computer vision and machine learning algorithm that is used to interpret the eyeblink and hand gesture signals captured by the camera. The software translates the signals into English, enabling caregivers and emergency responders to understand the message and provide appropriate assistance. Overall, the help alert system has the potential to greatly improve the quality of life and safety of elderly and differently-abled individuals, providing a simple and reliable means of communication in case of an emergency.

Programming Language:
	Python (spyder texteditor)

Modules Required:

1.	OpenCV
2.	FaceMeshDetetctor
3.	Tkinter
4.	Dlib
5.	Mediapipe
6.	Tensorflow

Files Required:
1.	gestures.names
2.	data.pickle
4.	mp_hand_gesture


Implementation Steps

1.	Install all the additional modules to the system using PIP install command in the Command prompt.
PIP install opencv -python
PIP install dlib
PIP install FaceMeshDetector
PIP install mediapipe
PIP install tensorflow



